{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"translate yer docs \u00b6 This repository translates yer docs into another language. This uses the Google Cloud Translate API, pandoc, and the panflute library to create a translation filter for Markdown files. See an example here: russian-rainbow-mind-machine (page contains documentation for the rainbow-mind-machine library translated into Russian). How This Repo is Organized \u00b6 How this repo is organized Part 1: Google Cloud Translate API Setup \u00b6 The Google Cloud Translate API is what makes this all possible. It is easier to translate documentation into Russian than it is to figure out how to parse Markdown programmatically with panflute and pandocs. Part 1: Setup Part 2: Pandoc \u00b6 We want to parse and translate Markdown written in English, and turn it into Markdown written in Russian. We use pandoc to parse the Markdown file and identify the bits that can be translated, pass them to the Google Cloud Translate API, and convert the translated text back into Markdown. Part 2: Pandoc: Pandoc: Markdown to JSON Pandoc: JSON to JSON Part 3: Panflute \u00b6 Panflute is a Python library for writing Pandoc filters. It is picky and tricky. Part 3: Panflute: Panflute: Translate Panflute: Page Elements Part 4: Pandoc \u00b6 The panflute filter will process JSON and return more JSON, so we have one last step, which is converting the final JSON document into Markdown. Part 4: Pandoc: JSON to Markdown Part 5: Testing \u00b6 You do want to write tests for all of this stuff, don't you? Part 5: Testing Part 6: Useful Links \u00b6 Part 6: Useful Links","title":"Home"},{"location":"#translate-yer-docs","text":"This repository translates yer docs into another language. This uses the Google Cloud Translate API, pandoc, and the panflute library to create a translation filter for Markdown files. See an example here: russian-rainbow-mind-machine (page contains documentation for the rainbow-mind-machine library translated into Russian).","title":"translate yer docs"},{"location":"#how-this-repo-is-organized","text":"How this repo is organized","title":"How This Repo is Organized"},{"location":"#part-1-google-cloud-translate-api-setup","text":"The Google Cloud Translate API is what makes this all possible. It is easier to translate documentation into Russian than it is to figure out how to parse Markdown programmatically with panflute and pandocs. Part 1: Setup","title":"Part 1: Google Cloud Translate API Setup"},{"location":"#part-2-pandoc","text":"We want to parse and translate Markdown written in English, and turn it into Markdown written in Russian. We use pandoc to parse the Markdown file and identify the bits that can be translated, pass them to the Google Cloud Translate API, and convert the translated text back into Markdown. Part 2: Pandoc: Pandoc: Markdown to JSON Pandoc: JSON to JSON","title":"Part 2: Pandoc"},{"location":"#part-3-panflute","text":"Panflute is a Python library for writing Pandoc filters. It is picky and tricky. Part 3: Panflute: Panflute: Translate Panflute: Page Elements","title":"Part 3: Panflute"},{"location":"#part-4-pandoc","text":"The panflute filter will process JSON and return more JSON, so we have one last step, which is converting the final JSON document into Markdown. Part 4: Pandoc: JSON to Markdown","title":"Part 4: Pandoc"},{"location":"#part-5-testing","text":"You do want to write tests for all of this stuff, don't you? Part 5: Testing","title":"Part 5: Testing"},{"location":"#part-6-useful-links","text":"Part 6: Useful Links","title":"Part 6: Useful Links"},{"location":"Links/","text":"Useful Links \u00b6 Markdown to structured JSON using pandoc: Text.Pandoc.JSON How to write Pandoc filters using Python: pandocfilters Example reading from stdin: pandoc -t json -s | ./caps.py | pandoc -f json Link to examples: pandocfilters examples caps.py requests library Python: requests quickstart >>> r = requests.put('http://httpbin.org/put', data = {'key':'value'}) pandocfilters pandocfilters also see but i don't want to learn haskell on pandoc.org.","title":"Links"},{"location":"Links/#useful-links","text":"Markdown to structured JSON using pandoc: Text.Pandoc.JSON How to write Pandoc filters using Python: pandocfilters Example reading from stdin: pandoc -t json -s | ./caps.py | pandoc -f json Link to examples: pandocfilters examples caps.py requests library Python: requests quickstart >>> r = requests.put('http://httpbin.org/put', data = {'key':'value'}) pandocfilters pandocfilters also see but i don't want to learn haskell on pandoc.org.","title":"Useful Links"},{"location":"Organization/","text":"Here is a rundown of the directory structure of translate the docs: Documentation \u00b6 All of the documentation for how to translate the docs lives in markdown files in docs/ . This is converted to HTML documentation using mkdocs . The configuration for mkdocs is in mkdocs.yml . The mkdocs theme used is mkdocs-material, which is in the git submodule mkdocs-material/ . The static content is on the gh-pages branch and is hosted on https://pages.charlesreid1.com/ and on Github Pages. Translation \u00b6 The document is first parsed with pandoc to convert markdown to JSON. The JSON is passed to a panflute filter, which processes the text. Translation magic happens using the Google Cloud Translate API, which is called by the panflute filter. Pandoc is used to convert the JSON back to (translated) markdown. Plans \u00b6 The tool in this repository (the pandoc filter) will eventually become a command line tool that can be run in-place from any repository, and the translated markdown deposited into a new directory. This requires one major design change: rather than using pandoc and applying filters from the command line, we must call the pandoc API from Python directly. Then we can define the filter as part of the command line tool, and when we call the translate the docs tool, it applies the filter in-place. The end result, for the user, is the ability to run a single command that will translate their docs: $ translate_the_docs --list-languages ru de es fr ar ... $ translate_the_docs Before we can translate your docs, we will start with a few questions. What directory contains your current markdown docs? Leave empty for default: docs Answer: docs What language do you want to translate your markdown docs into? Type ? for a list of languages. Answer: ? Possible languages: ru, de, es, fr, ar, ... What language do you want to translate your markdown docs into? Type ? for a list of languages. Answer: ru What directory do you want to contain your translated markdown docs? Leave empty for default: ru_docs Answer: Translating... Done! Or set with command line options: $ translate_the_docs --source=doc/ --target=ru_docs --language=ru","title":"How This Repo is Organized"},{"location":"Organization/#documentation","text":"All of the documentation for how to translate the docs lives in markdown files in docs/ . This is converted to HTML documentation using mkdocs . The configuration for mkdocs is in mkdocs.yml . The mkdocs theme used is mkdocs-material, which is in the git submodule mkdocs-material/ . The static content is on the gh-pages branch and is hosted on https://pages.charlesreid1.com/ and on Github Pages.","title":"Documentation"},{"location":"Organization/#translation","text":"The document is first parsed with pandoc to convert markdown to JSON. The JSON is passed to a panflute filter, which processes the text. Translation magic happens using the Google Cloud Translate API, which is called by the panflute filter. Pandoc is used to convert the JSON back to (translated) markdown.","title":"Translation"},{"location":"Organization/#plans","text":"The tool in this repository (the pandoc filter) will eventually become a command line tool that can be run in-place from any repository, and the translated markdown deposited into a new directory. This requires one major design change: rather than using pandoc and applying filters from the command line, we must call the pandoc API from Python directly. Then we can define the filter as part of the command line tool, and when we call the translate the docs tool, it applies the filter in-place. The end result, for the user, is the ability to run a single command that will translate their docs: $ translate_the_docs --list-languages ru de es fr ar ... $ translate_the_docs Before we can translate your docs, we will start with a few questions. What directory contains your current markdown docs? Leave empty for default: docs Answer: docs What language do you want to translate your markdown docs into? Type ? for a list of languages. Answer: ? Possible languages: ru, de, es, fr, ar, ... What language do you want to translate your markdown docs into? Type ? for a list of languages. Answer: ru What directory do you want to contain your translated markdown docs? Leave empty for default: ru_docs Answer: Translating... Done! Or set with command line options: $ translate_the_docs --source=doc/ --target=ru_docs --language=ru","title":"Plans"},{"location":"PandocA/","text":"This page covers the pandoc Markdown to JSON step. Using the Pandoc API (New Way) \u00b6 (In progress) From the Command Line (Old Way) \u00b6 We use pandoc to convert structured Markdown into JSON. This is done using the -f flag to specify the input format and the -t flag to specify the target format: pandoc -t json -f gfm my_markdown_file.md Here, we use gfm (Github-flavored markdown). We can also read documents from stdin using the -s flag: cat my_markdown_file.md | pandoc -t json -f gfm -s The resulting JSON is ready to be parsed using a pandoc filter. Note that if you wish to visualize the structure of the JSON before processing it further, you can pipe it to python -m json.tool , which nicely formats the JSON for printing and visualizing: cat my_markdown_file.md | pandoc -t json -f gfm -s | python -m json.tool","title":"Pandoc: Markdown to JSON"},{"location":"PandocA/#using-the-pandoc-api-new-way","text":"(In progress)","title":"Using the Pandoc API (New Way)"},{"location":"PandocA/#from-the-command-line-old-way","text":"We use pandoc to convert structured Markdown into JSON. This is done using the -f flag to specify the input format and the -t flag to specify the target format: pandoc -t json -f gfm my_markdown_file.md Here, we use gfm (Github-flavored markdown). We can also read documents from stdin using the -s flag: cat my_markdown_file.md | pandoc -t json -f gfm -s The resulting JSON is ready to be parsed using a pandoc filter. Note that if you wish to visualize the structure of the JSON before processing it further, you can pipe it to python -m json.tool , which nicely formats the JSON for printing and visualizing: cat my_markdown_file.md | pandoc -t json -f gfm -s | python -m json.tool","title":"From the Command Line (Old Way)"},{"location":"PandocB/","text":"This page covers the pandoc JSON to JSON step. To translate Markdown from English to Russian, we use pandoc to parse the Markdown file and extract the text that needs to be translated. Specifically, we write a JSON-to-JSON pandoc filter using panflute , a Python library for writing pandoc filters. Filtering with the Pandoc API (New Way) \u00b6 (In progress) Filtering from the Command Line (Old Way) \u00b6 The syntax is as follows: cat my_markdown_file.md | pandoc -t json -f gfm -s | filters/my_filter.py The convention for panflute filters is that the JSON document is passed into the panflute filter one component at a time. If the filter does not return anything, the document element will be used as-is in the final document. If a new document element is returned, it is used in place of the old document element.","title":"Pandoc: JSON to JSON"},{"location":"PandocB/#filtering-with-the-pandoc-api-new-way","text":"(In progress)","title":"Filtering with the Pandoc API (New Way)"},{"location":"PandocB/#filtering-from-the-command-line-old-way","text":"The syntax is as follows: cat my_markdown_file.md | pandoc -t json -f gfm -s | filters/my_filter.py The convention for panflute filters is that the JSON document is passed into the panflute filter one component at a time. If the filter does not return anything, the document element will be used as-is in the final document. If a new document element is returned, it is used in place of the old document element.","title":"Filtering from the Command Line (Old Way)"},{"location":"PandocC/","text":"Pandoc Parser: JSON-to-Markdown Parser \u00b6 To return everything back into Markdown, the last step of the pipeline is to add another call to pandoc, but with the formats reversed, so that it will turn JSON back into Markdown: cat shepherd.md | pandoc -t json -f gfm -s | ./panflute_rooskie.py | pandoc -f json -t gfm -s > shepherd_ru.md","title":"Pandoc: JSON to Markdown"},{"location":"PandocC/#pandoc-parser-json-to-markdown-parser","text":"To return everything back into Markdown, the last step of the pipeline is to add another call to pandoc, but with the formats reversed, so that it will turn JSON back into Markdown: cat shepherd.md | pandoc -t json -f gfm -s | ./panflute_rooskie.py | pandoc -f json -t gfm -s > shepherd_ru.md","title":"Pandoc Parser: JSON-to-Markdown Parser"},{"location":"PanfluteA/","text":"To translate Markdown text to Russian, we want to look for Para (paragraph) components, and extract the text from each paragraph as a string. cat shepherd.md | pandoc -t json -f gfm -s | filters/translate.py The translate.py panflute filter determines what text to translate and calls the Google Cloud Translate API to do the translating. We use the Google Cloud Translate API using a Python client library that they provide, rather than fussing with assembling our own payloads and using the requests library. filters/translate.py : from panflute import * from google.cloud import translate def translate_document ( elem , doc ): ... def main ( doc = None ): return run_filter ( translate_document , doc = doc ) if __name__ == \"__main__\" : main () When we run this, it passes each document element through translate_document() . Two things we wnat to do up front: Extract links (these are problematic for translation, we deal with them by removing the link from the inline text and including a list at the bottom of the document of the (translated) original link text, plus the link itself. Search for paragraphs of text, or headings, and replace text with a translation. To do the first, we define a function called strip_links() , which will strip out all the links and add them to the bottom of the document (more on this in a minute). We pass this function to elem.walk() to apply it to every element underneath the current element. This means we can write the strip_links() function in a similar way to the translate_document() function: look for specific types of elements, and modify them accordingly. def translate_document ( elem , doc ): # Walk it and look for links first elem . walk ( strip_links ) ... Another thing we want to do is translate paragraph text from Russian to English. We use stringify to turn a list of Str and Space objects into a regular string: def translate_document ( elem , doc ): # Walk it and look for links first elem . walk ( strip_links ) if type ( elem ) == Para : english = stringify ( doc ) translation = english_to_X ( english ) ... The english_to_X() function (more on this shortly) will use the Google Cloud Translate API to translate English to our language of choice. This requires an API key with Google Cloud (see Setup ). The translate function will return unicode text. This must be turned back into structured text that pandoc understands, so we have to wrap words in Str() and replace spaces with Space objects. To do this easily with a string in panflute, use convert_text() : english = stringify(elem) rooskie = english_to_russian(english) new_elems = convert_text(rooskie,input_format='markdown') return new_elems To get Google Cloud Translate API working properly, you must export an environment variable $GOOGLE_APPLICATION_CREDENTIALS that points to a JSON file with your API keys EACH TIME YOU RUN THE SCRIPT!!! ############################################ ############################################ ############## ############## ############## NOTE ############## ############## ############## ## ## This step is required for the translate ## API calls to work. Don't leave this out. ## ############################################ ############################################ export GOOGLE_APPLICATION_CREDENTIALS=/path/to/project-key-00000.json","title":"Panflute: Translate"},{"location":"PanfluteB/","text":"One of the pain points of translating a document is figuring out what to do with page elements. Links \u00b6 Lists \u00b6 Images \u00b6 Headers \u00b6 Links \u00b6 Take hyperlinks as an example. Here's how we deal with it: We have a prepare() method in our panflute filter that is run before the document filter is applied, and a finalize() method that is run after the document filter is applied. The prepare method initializes an empty list to hold links. As we parse each section of the document, we look for links, and when we find a link, we add the link to a list. When the text is translated, links are stripped out and the original link text becomes plain text again. Rather than try and determine which words in the translation map to the original link text, we simply aggregate the links at the bottom of the document. Each link includes a translation of the original link text that is a link to the original link. Panflute Filter \u00b6 Let's cover a bit more of the panflute magic that makes all of that happen. This relies on two additional methods for the filter: prepare() and finalize() . The prepare method just creates an empty list that will be used to store all of the link elements in the document: def prepare(doc): doc.linklist = [] We call the elem.walk() method on each element of the document, so we have a chance to see each element and determine if it is a link. If it is, we keep it simple and just save the entire element: def strip_links(elem,doc): \"\"\" Each link will be stripped in the translation process. Save them for the end. \"\"\" if isinstance(elem,Link): doc.linklist.append(elem)","title":"Panflute: Page Elements"},{"location":"PanfluteB/#links","text":"","title":"Links"},{"location":"PanfluteB/#lists","text":"","title":"Lists"},{"location":"PanfluteB/#images","text":"","title":"Images"},{"location":"PanfluteB/#headers","text":"","title":"Headers"},{"location":"PanfluteB/#links_1","text":"Take hyperlinks as an example. Here's how we deal with it: We have a prepare() method in our panflute filter that is run before the document filter is applied, and a finalize() method that is run after the document filter is applied. The prepare method initializes an empty list to hold links. As we parse each section of the document, we look for links, and when we find a link, we add the link to a list. When the text is translated, links are stripped out and the original link text becomes plain text again. Rather than try and determine which words in the translation map to the original link text, we simply aggregate the links at the bottom of the document. Each link includes a translation of the original link text that is a link to the original link.","title":"Links"},{"location":"PanfluteB/#panflute-filter","text":"Let's cover a bit more of the panflute magic that makes all of that happen. This relies on two additional methods for the filter: prepare() and finalize() . The prepare method just creates an empty list that will be used to store all of the link elements in the document: def prepare(doc): doc.linklist = [] We call the elem.walk() method on each element of the document, so we have a chance to see each element and determine if it is a link. If it is, we keep it simple and just save the entire element: def strip_links(elem,doc): \"\"\" Each link will be stripped in the translation process. Save them for the end. \"\"\" if isinstance(elem,Link): doc.linklist.append(elem)","title":"Panflute Filter"},{"location":"Setup/","text":"Setup \u00b6 Rundown of necessary setup steps: Create Google Cloud account Enable Googe Cloud Translate API Set up gcloud command line tool Test gcloud command line tool Create Google Cloud Account \u00b6 Creating a Google Cloud account requires a credit card. Obtaining a credit card is generally straightforward, and simply involves burrowing your way into the corporate bureaucracy by getting a job in an IT department. Academic institutions provide an optimal environment for obtaining a credit card to carry out sanctioned bot flock activities. Enable API \u00b6 Enable the Google Cloud Translate API here . Set Up Command Line Tool \u00b6 The Google Cloud SDK provides a command line tool that has utilities for interacting with the APIs. The prior step will give you a JSON key file. Associate this with the command line tool using the auth activate-service-account verb: gcloud auth activate-service-account --key-file=[PATH] Set this permanently by setting the location of the key file using an environment variable: export GOOGLE_APPLICATION_CREDENTIALS=${PWD}/krash.json Test Command Line Tool \u00b6 The API endpoint we will use is: https://translation.googleapis.com/language/translate/v2 To call this endpoint, we have to include a payload containing our API key, which we obtained earlier when we enabled the API. The gcloud tool provides a way to insert credentials easily: The command curl -s -X POST -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer \"$(gcloud auth print-access-token) \\ --data \"{ 'q':'Rainbow mind machine is extendable to keep bots from becoming boring. There are only two components to extend. These two components have a simple and clear order of function calls. Rainbow mind machine uses sensible defaults.', 'source': 'en', 'target': 'ru', 'format': 'text' }\" \"https://translation.googleapis.com/language/translate/v2\" should yield the result: { \"data\": { \"translations\": [ { \"translatedText\": \"\u0420\u0430\u0434\u0443\u0436\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430 \u0440\u0430\u0437\u0443\u043c\u0430 \u0440\u0430\u0441\u0448\u0438\u0440\u044f\u0435\u043c\u0430, \u0447\u0442\u043e\u0431\u044b \u0431\u043e\u0442\u044b \u043d\u0435 \u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438\u0441\u044c \u0441\u043a\u0443\u0447\u043d\u044b\u043c\u0438. \u0420\u0430\u0441\u0448\u0438\u0440\u044f\u044e\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u0432\u0430 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u0430. \u042d\u0442\u0438 \u0434\u0432\u0430 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u0430 \u0438\u043c\u0435\u044e\u0442 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0438 \u043f\u043e\u043d\u044f\u0442\u043d\u044b\u0439 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0432\u044b\u0437\u043e\u0432\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0439. \u041c\u0430\u0448\u0438\u043d\u0430 Rainbow mind \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0440\u0430\u0437\u0443\u043c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e.\" } ] } } So far, so good.","title":"Setup"},{"location":"Setup/#setup","text":"Rundown of necessary setup steps: Create Google Cloud account Enable Googe Cloud Translate API Set up gcloud command line tool Test gcloud command line tool","title":"Setup"},{"location":"Setup/#create-google-cloud-account","text":"Creating a Google Cloud account requires a credit card. Obtaining a credit card is generally straightforward, and simply involves burrowing your way into the corporate bureaucracy by getting a job in an IT department. Academic institutions provide an optimal environment for obtaining a credit card to carry out sanctioned bot flock activities.","title":"Create Google Cloud Account"},{"location":"Setup/#enable-api","text":"Enable the Google Cloud Translate API here .","title":"Enable API"},{"location":"Setup/#set-up-command-line-tool","text":"The Google Cloud SDK provides a command line tool that has utilities for interacting with the APIs. The prior step will give you a JSON key file. Associate this with the command line tool using the auth activate-service-account verb: gcloud auth activate-service-account --key-file=[PATH] Set this permanently by setting the location of the key file using an environment variable: export GOOGLE_APPLICATION_CREDENTIALS=${PWD}/krash.json","title":"Set Up Command Line Tool"},{"location":"Setup/#test-command-line-tool","text":"The API endpoint we will use is: https://translation.googleapis.com/language/translate/v2 To call this endpoint, we have to include a payload containing our API key, which we obtained earlier when we enabled the API. The gcloud tool provides a way to insert credentials easily: The command curl -s -X POST -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer \"$(gcloud auth print-access-token) \\ --data \"{ 'q':'Rainbow mind machine is extendable to keep bots from becoming boring. There are only two components to extend. These two components have a simple and clear order of function calls. Rainbow mind machine uses sensible defaults.', 'source': 'en', 'target': 'ru', 'format': 'text' }\" \"https://translation.googleapis.com/language/translate/v2\" should yield the result: { \"data\": { \"translations\": [ { \"translatedText\": \"\u0420\u0430\u0434\u0443\u0436\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430 \u0440\u0430\u0437\u0443\u043c\u0430 \u0440\u0430\u0441\u0448\u0438\u0440\u044f\u0435\u043c\u0430, \u0447\u0442\u043e\u0431\u044b \u0431\u043e\u0442\u044b \u043d\u0435 \u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438\u0441\u044c \u0441\u043a\u0443\u0447\u043d\u044b\u043c\u0438. \u0420\u0430\u0441\u0448\u0438\u0440\u044f\u044e\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u0432\u0430 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u0430. \u042d\u0442\u0438 \u0434\u0432\u0430 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u0430 \u0438\u043c\u0435\u044e\u0442 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0438 \u043f\u043e\u043d\u044f\u0442\u043d\u044b\u0439 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0432\u044b\u0437\u043e\u0432\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0439. \u041c\u0430\u0448\u0438\u043d\u0430 Rainbow mind \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0440\u0430\u0437\u0443\u043c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e.\" } ] } } So far, so good.","title":"Test Command Line Tool"},{"location":"Testing/","text":"Testing \u00b6 To test the pandoc filter to make sure it is working, you can create some Markdown in a file or from the command line, and feed it through pandoc and into the filter: $ echo \"This is a [paragraph](https://example.com) of markdown text.\" | pandoc -t json -f gfm -s | ./ruskie.py","title":"Testing"},{"location":"Testing/#testing","text":"To test the pandoc filter to make sure it is working, you can create some Markdown in a file or from the command line, and feed it through pandoc and into the filter: $ echo \"This is a [paragraph](https://example.com) of markdown text.\" | pandoc -t json -f gfm -s | ./ruskie.py","title":"Testing"}]}